{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat==0.4.0.dev11 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (0.4.0.dev11)\n",
      "Requirement already satisfied: autogen-ext==0.4.0.dev11 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-ext[openai]==0.4.0.dev11) (0.4.0.dev11)\n",
      "Requirement already satisfied: autogen-core==0.4.0.dev11 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-agentchat==0.4.0.dev11) (0.4.0.dev11)\n",
      "Requirement already satisfied: aiofiles in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-ext[openai]==0.4.0.dev11) (24.1.0)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-ext[openai]==0.4.0.dev11) (1.57.4)\n",
      "Requirement already satisfied: aioconsole in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (0.8.1)\n",
      "Requirement already satisfied: aiohttp in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (3.11.10)\n",
      "Requirement already satisfied: asyncio-atexit in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.0.1)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.27.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.27.0)\n",
      "Requirement already satisfied: pillow in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (11.0.0)\n",
      "Requirement already satisfied: protobuf~=4.25.1 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (4.25.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2.10.3)\n",
      "Requirement already satisfied: tiktoken in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen-ext[openai]==0.4.0.dev11) (0.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from opentelemetry-api~=1.27.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from opentelemetry-api~=1.27.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (8.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2.27.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from aiohttp->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.18.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from tiktoken->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from tiktoken->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.27.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (1.17.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api~=1.27.0->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kiendoit/workspaces/ai-lab/autogen/myautogen/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->autogen-core==0.4.0.dev11->autogen-agentchat==0.4.0.dev11) (2.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'autogen-agentchat==0.4.0.dev11' 'autogen-ext[openai]==0.4.0.dev11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- weather_agent ----------\n",
      "[FunctionCall(id='call_4t6DeLWbnnlGHwkiyJxufWRx', arguments='{\"city\":\"New York\"}', name='get_weather')]\n",
      "[Prompt tokens: 76, Completion tokens: 16]\n",
      "---------- weather_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', call_id='call_4t6DeLWbnnlGHwkiyJxufWRx')]\n",
      "---------- weather_agent ----------\n",
      "The weather in New York is 73 degrees and Sunny.\n",
      "---------- weather_agent ----------\n",
      "The weather in New York is currently 73 degrees and sunny. TERMINATE\n",
      "[Prompt tokens: 114, Completion tokens: 17]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 190\n",
      "Total completion tokens: 33\n",
      "Duration: 2.11 seconds\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "# Define a tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    # Define an agent\n",
    "    weather_agent = AssistantAgent(\n",
    "        name=\"weather_agent\",\n",
    "        model_client=OpenAIChatCompletionClient(\n",
    "            model=\"gpt-4o\",\n",
    "            api_key=\"\",\n",
    "        ),\n",
    "        tools=[get_weather],\n",
    "    )\n",
    "\n",
    "    # Define termination condition\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "    # Define a team\n",
    "    agent_team = RoundRobinGroupChat([weather_agent], termination_condition=termination)\n",
    "\n",
    "    # Run the team and stream messages to the console\n",
    "    stream = agent_team.run_stream(task=\"What is the weather in New York?\")\n",
    "    await Console(stream)\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Tell me some jokes.\n",
      "---------- Assistant1 ----------\n",
      "Sure, here are a few jokes for you:\n",
      "\n",
      "1. Why don't scientists trust atoms?\n",
      "   Because they make up everything!\n",
      "\n",
      "2. What do you call fake spaghetti?\n",
      "   An impasta!\n",
      "\n",
      "3. Why did the scarecrow win an award?\n",
      "   Because he was outstanding in his field!\n",
      "\n",
      "4. What do you call a snowman with a six-pack?\n",
      "   An abdominal snowman!\n",
      "\n",
      "5. How do you organize a space party?\n",
      "   You planet!\n",
      "\n",
      "I hope these brought a smile to your face!\n",
      "[Prompt tokens: 33, Completion tokens: 104]\n",
      "---------- Assistant2 ----------\n",
      "Would you like to hear more jokes or anything else?\n",
      "[Prompt tokens: 139, Completion tokens: 12]\n",
      "---------- Assistant1 ----------\n",
      "Sure, here are a few more jokes for you:\n",
      "\n",
      "1. Why did the bicycle fall over?\n",
      "   Because it was two-tired!\n",
      "\n",
      "2. What do you get when you cross a snowman and a vampire?\n",
      "   Frostbite!\n",
      "\n",
      "3. How do you catch a squirrel?\n",
      "   Climb a tree and act like a nut!\n",
      "\n",
      "4. Why did the math book look sad?\n",
      "   Because it had too many problems!\n",
      "\n",
      "5. What did one ocean say to the other ocean?\n",
      "   Nothing, they just waved!\n",
      "\n",
      "Let me know if you want more!\n",
      "[Prompt tokens: 161, Completion tokens: 114]\n",
      "---------- Assistant2 ----------\n",
      "Why did the math book look sad? Because it had too many problems.\n",
      "\n",
      "Want to hear more?\n",
      "[Prompt tokens: 277, Completion tokens: 21]\n",
      "---------- Assistant1 ----------\n",
      "Here's another batch of jokes for you:\n",
      "\n",
      "1. What did the zero say to the eight?\n",
      "   Nice belt!\n",
      "\n",
      "2. Why are skeletons so calm?\n",
      "   Because nothing gets under their skin!\n",
      "\n",
      "3. Why did the golfer bring two pairs of pants?\n",
      "   In case he got a hole in one!\n",
      "\n",
      "4. How do astronomers organize a party?\n",
      "   They planet!\n",
      "\n",
      "5. What’s orange and sounds like a parrot?\n",
      "   A carrot!\n",
      "\n",
      "Enjoy! Let me know if you'd like to hear even more.\n",
      "[Prompt tokens: 308, Completion tokens: 106]\n",
      "---------- Assistant2 ----------\n",
      "TERMINATE\n",
      "[Prompt tokens: 416, Completion tokens: 4]\n",
      "---------- Summary ----------\n",
      "Number of messages: 7\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 1334\n",
      "Total completion tokens: 361\n",
      "Duration: 8.43 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\", \n",
    "        api_key=\"\"\n",
    "    )\n",
    "\n",
    "    agent1 = AssistantAgent(\"Assistant1\", model_client=model_client, system_message=\"I'm a first assistant. Do not include the word TERMINATE in your response.\")\n",
    "    agent2 = AssistantAgent(\"Assistant2\", model_client=model_client, system_message=\"I'm a second assistant. Once done, respond with TERMINATE\")\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "    team = RoundRobinGroupChat([agent1, agent2], termination_condition=termination)\n",
    "    await Console(team.run_stream(task=\"Tell me some jokes.\"))\n",
    "\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myautogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
